# VerbalizedSampling-ChatBot

Recently experimented with integrating Verbalized Sampling into a multi-mode LLM interface, and moreover added a little twist to it.

So the idea is instead of generating a single response, the system produces multiple candidate outputs, evaluates them, and selects the strongest one, according to their probability. This approach forces the LLM to generate creative, diverse and unpredictable responses.

The result was noticeably higher response diversity (close to 2Ã— in practical testing) and reduced repetitive patterns â€” a small but meaningful step toward mitigating early-stage mode collapse.

Built with FastAPI + Gemini + Streamlit, featuring:
* Session-based conversational memory
* Mode-aware behavioral toggles (normal ğŸ˜Š/ reasoning ğŸ¤¯/ valentine ğŸ’)
* Token-aware context trimming

Since it is Valentine's Day, so couldn't stop myself from adding an intriguing Valentine'S Mode, that prompts a distinct shift in the personality.

I also explored behavioral UX signaling:

* ğŸ’™ Aqua glow â†’ Reasoning mode (structured multi-candidate sampling)
* ğŸ’˜ Pink glow â†’ Valentine mode (stylistic personality shift)
* ğŸ˜Š Neutral â†’ Standard conversational mode

The glow isnâ€™t decorative â€” it visually communicates which behavioral mode generated the response, making experimentation transparent and intuitive.

Key takeaway: improving LLM behavior isnâ€™t always about changing the model â€” sometimes itâ€™s about changing how we sample and structure its reasoning.

